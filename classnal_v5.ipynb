{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-689f170023dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspikeFileIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dv import AedatFile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import spikeFileIO\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 하나당 한 클래스 사용\n",
    "class clustering:\n",
    "    def __init__(self, frame_size = 40000):\n",
    "        self.frame_size = frame_size\n",
    "        self.events = None\n",
    "        self.df = None\n",
    "        self.start_time = 0\n",
    "        \n",
    "        \n",
    "    def read_aedat_file(self, path):\n",
    "        with AedatFile(path) as f:\n",
    "            events = np.hstack([packet for packet in f['events'].numpy()])\n",
    "            timestamps, x, y, polarities = events['timestamp'], events['x'], events['y'], events['polarity']\n",
    "            self.events = events\n",
    "            self.timestamp_zeroization()\n",
    "            self.dflization()\n",
    "            return events\n",
    "        \n",
    "    #read_aedat_file에서 호출\n",
    "    def timestamp_zeroization(self):\n",
    "        temp = self.events['timestamp'][0]\n",
    "        for i in range(0,len(self.events['timestamp'])):\n",
    "            self.events['timestamp'][i]-=temp\n",
    "            \n",
    "    #read_aedat_file에서 호출\n",
    "    def dflization(self):\n",
    "        self.df = pd.DataFrame(self.events)\n",
    "            \n",
    "    \n",
    "    def cut_frame(self,start_time=0):\n",
    "        end_condition = self. df['timestamp'] <= start_time+self.frame_size\n",
    "        start_condition = self.df['timestamp'] >= start_time\n",
    "        #print('end_condition : {}'.format(end_condition))\n",
    "        #print('start_condition : {}'.format(start_condition))\n",
    "        target_df = self.df[end_condition & start_condition]\n",
    "        a = target_df.reset_index(drop=True)\n",
    "        a = self.time_nomalization(a)\n",
    "        return a\n",
    "    \n",
    "    def time_nomalization(self,frame):\n",
    "        temp=self.frame_size/150\n",
    "        cpy=pd.DataFrame.copy(frame)\n",
    "        for i in range(len(frame)):\n",
    "            cpy['timestamp'][i] = frame['timestamp'][i]/temp\n",
    "        return cpy\n",
    "    \n",
    "    def make_model(self,feature, eps=17,min_samples=100):\n",
    "        model = DBSCAN(eps=eps,min_samples=min_samples)\n",
    "        predict = pd.DataFrame(model.fit_predict(feature))\n",
    "        predict.columns=['predict']\n",
    "        # concatenate labels to df as a new column\n",
    "        r = pd.concat([feature,predict],axis=1)\n",
    "        return r\n",
    "    \n",
    "        \n",
    "        #그리기\n",
    "    \n",
    "def draw(r):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(r['x'],r['y'],r['timestamp'],c=r['predict'],alpha=0.5)\n",
    "    ax.view_init(270,270)\n",
    "    ax.set_xlabel('Sepal lenth')\n",
    "    ax.set_ylabel('Sepal width')\n",
    "    ax.set_zlabel('Petal length')\n",
    "    \n",
    "    plt.show()\n",
    "    return r\n",
    "        \n",
    "def save(r,i):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(r['x'],r['y'],r['timestamp'],c=r['predict'],alpha=0.5)\n",
    "    ax.view_init(270,270)\n",
    "    ax.set_xlabel('Sepal lenth')\n",
    "    ax.set_ylabel('Sepal width')\n",
    "    ax.set_zlabel('Petal length')\n",
    "    plt.savefig(\"./save/d/test{}.png\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#함수화\n",
    "\n",
    "#판다스 배열들의 리스트 만들기\n",
    "def event_output(p1):\n",
    "    cname = ['timestamp','x','y','polarity','_p1','_p2','predict']\n",
    "\n",
    "\n",
    "    r_list = []\n",
    "\n",
    "    #검출한거 개수만큼 미리 리스트 만들어놓기\n",
    "    r_list_size = p1['predict'].max(axis=0)\n",
    "    for j in range(r_list_size+1):\n",
    "        newp = pd.DataFrame(columns=cname)\n",
    "        r_list.append(newp)\n",
    "\n",
    "    for i in p1.index:\n",
    "        #print(p1.loc[i].values)\n",
    "        s=p1.loc[i].values.tolist()\n",
    "        if p1.loc[i,\"predict\"] == -1:\n",
    "            continue\n",
    "        r_list[p1.loc[i,\"predict\"]].loc[len(r_list[p1.loc[i,\"predict\"]])]=s\n",
    "\n",
    "    #print(r_list)\n",
    "    return r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_output(num,r_list):\n",
    "    #num은 출력될 파일이름(전체에서 파일 순서)\n",
    "    #r_list는 출력할 df 리스트\n",
    "    list_size=len(r_list)\n",
    "    \n",
    "    for i in range(0,list_size):\n",
    "        print(\"num : \"+str(num+i))\n",
    "        df=r_list[i]\n",
    "        \n",
    "        p_xEvent = df['x']\n",
    "        p_yEvent = df['y']\n",
    "        p_pEvent = df['polarity']\n",
    "        p_tEvent = df['timestamp']\n",
    "        #print(p_xEvent)\n",
    "        # print('yyyyyyy')\n",
    "        xEvent = []\n",
    "        yEvent = []\n",
    "        pEvent = []\n",
    "        tEvent = []\n",
    "        \n",
    "        xEvent = p_xEvent.tolist()\n",
    "        yEvent = p_yEvent.tolist()\n",
    "        pEvent = p_pEvent.tolist()\n",
    "        tEvent = p_tEvent.tolist()\n",
    "        \n",
    "        inputSpikes = spikeFileIO.event(xEvent, yEvent, pEvent, tEvent).toSpikeTensor(\n",
    "            torch.zeros((2, 346, 260, 3000)), samplingTime=0.1\n",
    "        )\n",
    "        anim = spikeFileIO.animTD(spikeFileIO.spikeArrayToEvent(inputSpikes.reshape((2, 346, 260, -1)).cpu().data.numpy()))\n",
    "        draw(df)\n",
    "        save(df,num+i)\n",
    "        df.to_csv(\"./csv/\"+str(num+i)+\".csv\")\n",
    "        \n",
    "    #반환값은 새로운 num\n",
    "    return num+list_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sslab\\anaconda3\\envs\\visual\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num : 1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-eb045e269365>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msg3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msg2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msg3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m#save(sg2,i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-2d0d3a5c4056>\u001b[0m in \u001b[0;36mcsv_output\u001b[1;34m(num, r_list)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         inputSpikes = spikeFileIO.event(xEvent, yEvent, pEvent, tEvent).toSpikeTensor(\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m346\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m260\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamplingTime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         )\n\u001b[0;32m     29\u001b[0m         \u001b[0manim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspikeFileIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manimTD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspikeFileIO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspikeArrayToEvent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputSpikes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m346\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m260\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "test2 = clustering()\n",
    "test2.read_aedat_file('./predata/newdata.aedat4')\n",
    "\n",
    "num = 1\n",
    "for i in range(1,2):\n",
    "    size=i*40000\n",
    "    sg1 = test2.cut_frame(size)\n",
    "    sg2 = test2.make_model(sg1)\n",
    "    sg3 = event_output(sg2)\n",
    "    num = csv_output(num,sg3)\n",
    "    #save(sg2,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
